{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'beck.beck_nnet_pvcorr' from '../classes/beck/beck_nnet_pvcorr.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys,os,copy,pdb,importlib\n",
    "sys.path.append('../classes')\n",
    "sys.path.append('../analysis')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tournament_new as tn\n",
    "import create_database as cd\n",
    "importlib.reload(tn)\n",
    "\n",
    "import beck.beck_game\n",
    "from importlib import reload\n",
    "reload(beck.beck_game)\n",
    "from beck.beck_game import BeckGame as Game\n",
    "game = Game(4,9,4)\n",
    "\n",
    "from arena import Arena\n",
    "from mcts import MCTS\n",
    "importlib.reload(tn)\n",
    "game = Game(4,9,4)\n",
    "all_p = pd.read_pickle(cd.DATABASE_LOC)\n",
    "\n",
    "# res = tn.merge_res_to_base()\n",
    "tournament_res = pd.read_pickle('/scratch/zz737/fiar/tournaments/ai_all_player_round_robin_base.pkl')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import metrics\n",
    "\n",
    "sys.path.append('..')\n",
    "from neural_net import NeuralNet\n",
    "from utils import *\n",
    "\n",
    "reload(beck.beck_nnet)\n",
    "from beck.beck_nnet import OthelloNNet, NNetWrapper\n",
    "\n",
    "import beck.beck_nnet_pvcorr as bnp\n",
    "reload(bnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import Pickler, Unpickler\n",
    "def load_data():\n",
    "    # load and organize data\n",
    "\n",
    "    weight_dir = '/scratch/zz737/fiar/tournaments/tournament_6/checkpoints_mcts100_cpuct2_id_1'\n",
    "    fn = 'checkpoint_55.pth.tar'\n",
    "    load_folder_file = (weight_dir,fn)\n",
    "\n",
    "    modelFile = os.path.join(load_folder_file[0], load_folder_file[1])\n",
    "    examplesFile = modelFile + \".examples\"\n",
    "    with open(examplesFile, \"rb\") as f:\n",
    "        trainExamplesHistory = Unpickler(f).load()\n",
    "\n",
    "\n",
    "    from random import shuffle\n",
    "    trainExamples = []\n",
    "    for e in trainExamplesHistory:\n",
    "        trainExamples.extend(e)\n",
    "    shuffle(trainExamples)\n",
    "    N_trainexs = len(trainExamples)\n",
    "    return trainExamples\n",
    "    # input_boards, target_pis, target_vs = list(zip(*trainExamples[:10]))\n",
    "    # input_boards = np.asarray(input_boards)\n",
    "    # target_pis = np.asarray(target_pis)\n",
    "    # target_vs = np.asarray(target_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict({\n",
    "    'lr': 0.001,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 64,\n",
    "    'cuda': False,\n",
    "    'num_channels': 512,\n",
    "    'wl2':0.0001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloNNet():\n",
    "    def __init__(self, game, args):\n",
    "        # game params\n",
    "        self.board_x, self.board_y = game.getBoardSize()\n",
    "        self.action_size = game.getActionSize()\n",
    "        self.args = args\n",
    "\n",
    "        # Neural Net\n",
    "        self.input_boards = Input(shape=(self.board_x, self.board_y))    # s: batch_size x board_x x board_y\n",
    "\n",
    "        x_image = Reshape((self.board_x, self.board_y, 1))(self.input_boards)                # batch_size  x board_x x board_y x 1\n",
    "        h_conv1 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(x_image)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(h_conv1)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='valid', use_bias=False)(h_conv2)))        # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 2, padding='valid', use_bias=False)(h_conv3)))        # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "        h_conv4_flat = Flatten()(h_conv4)       \n",
    "        s_fc1 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc1))))          # batch_size x 1024\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc2)   # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc2)                    # batch_size x 1\n",
    "\n",
    "        self.model = Model(inputs=self.input_boards, outputs=[self.pi, self.v])\n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(args.lr))\n",
    " \n",
    "class OthelloNNet_wl2():\n",
    "    def __init__(self, game, args):\n",
    "        # game params\n",
    "        self.board_x, self.board_y = game.getBoardSize()\n",
    "        self.action_size = game.getActionSize()\n",
    "        self.args = args\n",
    "\n",
    "        # Neural Net\n",
    "        self.input_boards = Input(shape=(self.board_x, self.board_y))    # s: batch_size x board_x x board_y\n",
    "\n",
    "        x_image = Reshape((self.board_x, self.board_y, 1))(self.input_boards)                # batch_size  x board_x x board_y x 1\n",
    "        h_conv1 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(x_image)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(h_conv1)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='valid', use_bias=False)(h_conv2)))        # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 2, padding='valid', use_bias=False)(h_conv3)))        # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "        h_conv4_flat = Flatten()(h_conv4)       \n",
    "        s_fc1 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc1))))          # batch_size x 1024\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc2)   # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc2)                    # batch_size x 1\n",
    "        self.model = Model(inputs=self.input_boards, outputs=[self.pi, self.v])\n",
    "        \n",
    "        alpha = args.wl2\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
    "                layer.add_loss(lambda layer=layer: keras.regularizers.l2(alpha)(layer.kernel))\n",
    "            if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
    "                layer.add_loss(lambda layer=layer: keras.regularizers.l2(alpha)(layer.bias))\n",
    "        \n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(args.lr))\n",
    "\n",
    "class OthelloNNet_convhead():\n",
    "    def __init__(self, game, args):\n",
    "        # game params\n",
    "        self.board_x, self.board_y = game.getBoardSize()\n",
    "        self.action_size = game.getActionSize()\n",
    "        self.args = args\n",
    "\n",
    "        # Neural Net\n",
    "        self.input_boards = Input(shape=(self.board_x, self.board_y))    # s: batch_size x board_x x board_y\n",
    "\n",
    "        x_image = Reshape((self.board_x, self.board_y, 1))(self.input_boards)                # batch_size  x board_x x board_y x 1\n",
    "        h_conv1 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(x_image)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(h_conv1)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='valid', use_bias=False)(h_conv2)))        # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 2, padding='valid', use_bias=False)(h_conv3)))        # batch_size  x (board_x-3) x (board_y-3) x num_channels\n",
    "        \n",
    "        h_conv_pi = Activation('relu')(BatchNormalization(axis=3)(Conv2D(128, 2, padding='same', use_bias=False)(h_conv4)))        \n",
    "        h_conv_v = Activation('relu')(BatchNormalization(axis=3)(Conv2D(16, 2, padding='same', use_bias=False)(h_conv4)))        \n",
    "        \n",
    "        h_conv_pi_flat = Flatten()(h_conv_pi)\n",
    "        h_conv_v_flat = Flatten()(h_conv_v)\n",
    "        \n",
    "\n",
    "\n",
    "        s_fc_pi1 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv_pi_flat))))  # batch_size x 1024\n",
    "        s_fc_pi2 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc_pi1))))  # batch_size x 1024\n",
    "\n",
    "        s_fc_v1 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(h_conv_v_flat))))  # batch_size x 1024\n",
    "        \n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc_pi2)   # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc_v1)                    # batch_size x 1\n",
    "        \n",
    "        self.model = Model(inputs=self.input_boards, outputs=[self.pi, self.v])\n",
    "        \n",
    "#         alpha = 0.0001\n",
    "#         for layer in self.model.layers:\n",
    "#             if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
    "#                 layer.add_loss(lambda layer=layer: keras.regularizers.l2(alpha)(layer.kernel))\n",
    "#             if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
    "#                 layer.add_loss(lambda layer=layer: keras.regularizers.l2(alpha)(layer.bias))\n",
    "        \n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(args.lr))\n",
    "\n",
    "\n",
    "        \n",
    "class OthelloNNet_convsame():\n",
    "    def __init__(self, game, args):\n",
    "        # game params\n",
    "        self.board_x, self.board_y = game.getBoardSize()\n",
    "        self.action_size = game.getActionSize()\n",
    "        self.args = args\n",
    "\n",
    "        # Neural Net\n",
    "        self.input_boards = Input(shape=(self.board_x, self.board_y))    # s: batch_size x board_x x board_y\n",
    "\n",
    "        x_image = Reshape((self.board_x, self.board_y, 1))(self.input_boards)                # batch_size  x board_x x board_y x 1\n",
    "        h_conv1 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(x_image)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(h_conv1)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(h_conv2)))        # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(h_conv3)))        # batch_size  x (board_x-3) x (board_y-3) x num_channels\n",
    "        \n",
    "        h_conv_pi = Activation('relu')(BatchNormalization(axis=3)(Conv2D(128, 2, padding='same', use_bias=False)(h_conv4)))        \n",
    "        h_conv_v = Activation('relu')(BatchNormalization(axis=3)(Conv2D(16, 2, padding='same', use_bias=False)(h_conv4)))        \n",
    "        \n",
    "        h_conv_pi_flat = Flatten()(h_conv_pi)\n",
    "        h_conv_v_flat = Flatten()(h_conv_v)\n",
    "        \n",
    "\n",
    "\n",
    "        s_fc_pi1 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(1024, use_bias=False)(h_conv_pi_flat))))  # batch_size x 1024\n",
    "        s_fc_pi2 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(s_fc_pi1))))  # batch_size x 1024\n",
    "\n",
    "        s_fc_v1 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(512, use_bias=False)(h_conv_v_flat))))  # batch_size x 1024\n",
    "        \n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc_pi2)   # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='tanh', name='v')(s_fc_v1)                    # batch_size x 1\n",
    "        \n",
    "        self.model = Model(inputs=self.input_boards, outputs=[self.pi, self.v])\n",
    "        \n",
    "        \n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(args.lr))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "args = dotdict({\n",
    "    'lr': 0.001,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 64,\n",
    "    'cuda': False,\n",
    "    'num_channels': 256,\n",
    "    'wl2':0.0001,\n",
    "    'n_res':19\n",
    "})\n",
    "\n",
    "def bn_relu(inputs: Tensor)-> Tensor:\n",
    "    bn = BatchNormalization(axis=3)(inputs)\n",
    "    relu = ReLU()(bn)\n",
    "    return relu\n",
    "\n",
    "def residual_block(x: Tensor, filters: int, kernel_size: int=3)->Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size, strides=1, filters=filters, padding='same')(x)\n",
    "    y = bn_relu(y)\n",
    "    y = Conv2D(kernel_size=kernel_size, strides=1, filters=filters, padding='same')(y)\n",
    "    y = BatchNormalization(axis=3)(y)\n",
    "    out = Add()([x,y])\n",
    "    out = ReLU()(out)\n",
    "    return out\n",
    "    \n",
    "class OthelloNNet_resnet():\n",
    "    def __init__(self, game, args):\n",
    "        self.board_x, self.board_y = game.getBoardSize()\n",
    "        self.action_size = game.getActionSize()\n",
    "        self.args = args\n",
    "\n",
    "        # Neural Net\n",
    "        self.input_boards = Input(shape=(self.board_x, self.board_y))    # s: batch_size x board_x x board_y\n",
    "\n",
    "        x_image = Reshape((self.board_x, self.board_y, 1))(self.input_boards)                # batch_size  x board_x x board_y x 1\n",
    "        t = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 3, padding='same', use_bias=False)(x_image)))         # batch_size  x board_x x board_y x num_channels\n",
    "        \n",
    "        for n in range(args.n_res):\n",
    "            t = residual_block(t,filters=args.num_channels,kernel_size=3)\n",
    "        \n",
    "        # policy head\n",
    "        pt = Conv2D(filters=2,kernel_size=1,strides=1,padding='same')(t)\n",
    "        pt = bn_relu(pt)\n",
    "        pt = Flatten()(pt)\n",
    "        self.pi = Dense(self.action_size,activation='softmax',name='pi')(pt)\n",
    "        \n",
    "        # value head\n",
    "        vt = Conv2D(filters=1,kernel_size=1,strides=1,padding='same')(t)\n",
    "        vt = bn_relu(vt)\n",
    "        vt = Flatten()(vt)\n",
    "        vt = Dense(256, activation='relu')(vt)\n",
    "        self.v = Dense(1,activation='tanh',name='v')(vt)\n",
    "\n",
    "        self.model = Model(inputs=self.input_boards, outputs=[self.pi, self.v])\n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(args.lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OthelloNNet_resnet at 0x14a3adf8d890>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OthelloNNet_resnet(game,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello_dict = dict(old = OthelloNNet(game,args),\n",
    "     wl2 = OthelloNNet_wl2(game,args),\n",
    "     convhead = OthelloNNet_convhead(game,args),\n",
    "     convsame = OthelloNNet_convsame(game,args),\n",
    "    res = OthelloNNet_resnet(game,args)\n",
    "    )\n",
    "\n",
    "nnet_dict = {}\n",
    "for name,onet in othello_dict.items():\n",
    "    nnet_dict[name] = NNetWrapper(game, args=args, nnet=othello_dict[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.0021708666>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet_dict['wl2'].nnet.model.layers[2].losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========TRAINING old=========\n",
      "Epoch 1/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 1.5902 - pi_loss: 1.4080 - v_loss: 0.1822\n",
      "Epoch 2/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 1.0577 - pi_loss: 0.9152 - v_loss: 0.1425\n",
      "Epoch 3/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.9563 - pi_loss: 0.8209 - v_loss: 0.1353\n",
      "Epoch 4/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.8878 - pi_loss: 0.7584 - v_loss: 0.1294\n",
      "Epoch 5/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.8380 - pi_loss: 0.7136 - v_loss: 0.1244\n",
      "Epoch 6/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.7979 - pi_loss: 0.6779 - v_loss: 0.1200\n",
      "Epoch 7/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.7658 - pi_loss: 0.6499 - v_loss: 0.1159\n",
      "Epoch 8/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.7430 - pi_loss: 0.6306 - v_loss: 0.1125\n",
      "Epoch 9/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.7226 - pi_loss: 0.6137 - v_loss: 0.1089\n",
      "Epoch 10/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.7073 - pi_loss: 0.6008 - v_loss: 0.1066\n",
      "Epoch 11/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6948 - pi_loss: 0.5913 - v_loss: 0.1035\n",
      "Epoch 12/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6851 - pi_loss: 0.5833 - v_loss: 0.1018\n",
      "Epoch 13/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6761 - pi_loss: 0.5764 - v_loss: 0.0996\n",
      "Epoch 14/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6686 - pi_loss: 0.5707 - v_loss: 0.0979\n",
      "Epoch 15/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6624 - pi_loss: 0.5658 - v_loss: 0.0966\n",
      "Epoch 16/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6569 - pi_loss: 0.5613 - v_loss: 0.0956\n",
      "Epoch 17/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6510 - pi_loss: 0.5571 - v_loss: 0.0939\n",
      "Epoch 18/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6469 - pi_loss: 0.5537 - v_loss: 0.0932\n",
      "Epoch 19/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6434 - pi_loss: 0.5510 - v_loss: 0.0924\n",
      "Epoch 20/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6392 - pi_loss: 0.5477 - v_loss: 0.0915\n",
      "Epoch 21/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6359 - pi_loss: 0.5450 - v_loss: 0.0909\n",
      "Epoch 22/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6330 - pi_loss: 0.5433 - v_loss: 0.0896\n",
      "Epoch 23/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6309 - pi_loss: 0.5419 - v_loss: 0.0890\n",
      "Epoch 24/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6278 - pi_loss: 0.5399 - v_loss: 0.0879\n",
      "Epoch 25/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6254 - pi_loss: 0.5376 - v_loss: 0.0877\n",
      "Epoch 26/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6232 - pi_loss: 0.5360 - v_loss: 0.0873\n",
      "Epoch 27/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6217 - pi_loss: 0.5349 - v_loss: 0.0868\n",
      "Epoch 28/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6195 - pi_loss: 0.5336 - v_loss: 0.0859\n",
      "Epoch 29/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6182 - pi_loss: 0.5328 - v_loss: 0.0854\n",
      "Epoch 30/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6159 - pi_loss: 0.5307 - v_loss: 0.0852\n",
      "Epoch 31/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6159 - pi_loss: 0.5309 - v_loss: 0.0850\n",
      "Epoch 32/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6138 - pi_loss: 0.5294 - v_loss: 0.0844\n",
      "Epoch 33/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6127 - pi_loss: 0.5287 - v_loss: 0.0839\n",
      "Epoch 34/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6110 - pi_loss: 0.5267 - v_loss: 0.0843\n",
      "Epoch 35/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6099 - pi_loss: 0.5265 - v_loss: 0.0834\n",
      "Epoch 36/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6092 - pi_loss: 0.5257 - v_loss: 0.0834\n",
      "Epoch 37/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6086 - pi_loss: 0.5253 - v_loss: 0.0832\n",
      "Epoch 38/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6071 - pi_loss: 0.5243 - v_loss: 0.0828\n",
      "Epoch 39/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6063 - pi_loss: 0.5239 - v_loss: 0.0824\n",
      "Epoch 40/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6055 - pi_loss: 0.5234 - v_loss: 0.0820\n",
      "Epoch 41/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6039 - pi_loss: 0.5218 - v_loss: 0.0822\n",
      "Epoch 42/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6039 - pi_loss: 0.5219 - v_loss: 0.0820\n",
      "Epoch 43/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6032 - pi_loss: 0.5216 - v_loss: 0.0816\n",
      "Epoch 44/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6019 - pi_loss: 0.5209 - v_loss: 0.0811\n",
      "Epoch 45/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6001 - pi_loss: 0.5192 - v_loss: 0.0809\n",
      "Epoch 46/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6009 - pi_loss: 0.5198 - v_loss: 0.0811\n",
      "Epoch 47/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.6004 - pi_loss: 0.5194 - v_loss: 0.0810\n",
      "Epoch 48/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5999 - pi_loss: 0.5192 - v_loss: 0.0806\n",
      "Epoch 49/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5984 - pi_loss: 0.5178 - v_loss: 0.0806\n",
      "Epoch 50/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5981 - pi_loss: 0.5180 - v_loss: 0.0801\n",
      "Epoch 51/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5981 - pi_loss: 0.5177 - v_loss: 0.0804\n",
      "Epoch 52/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5974 - pi_loss: 0.5171 - v_loss: 0.0803\n",
      "Epoch 53/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5963 - pi_loss: 0.5164 - v_loss: 0.0799\n",
      "Epoch 54/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5964 - pi_loss: 0.5164 - v_loss: 0.0800\n",
      "Epoch 55/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5956 - pi_loss: 0.5158 - v_loss: 0.0798\n",
      "Epoch 56/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5961 - pi_loss: 0.5166 - v_loss: 0.0795\n",
      "Epoch 57/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5946 - pi_loss: 0.5153 - v_loss: 0.0793\n",
      "Epoch 58/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5944 - pi_loss: 0.5150 - v_loss: 0.0794\n",
      "Epoch 59/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5940 - pi_loss: 0.5149 - v_loss: 0.0792\n",
      "Epoch 60/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5933 - pi_loss: 0.5141 - v_loss: 0.0792\n",
      "Epoch 61/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5938 - pi_loss: 0.5146 - v_loss: 0.0792\n",
      "Epoch 62/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5931 - pi_loss: 0.5141 - v_loss: 0.0789\n",
      "Epoch 63/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5925 - pi_loss: 0.5136 - v_loss: 0.0789\n",
      "Epoch 64/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5920 - pi_loss: 0.5133 - v_loss: 0.0786\n",
      "Epoch 65/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5911 - pi_loss: 0.5124 - v_loss: 0.0787\n",
      "Epoch 66/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5909 - pi_loss: 0.5123 - v_loss: 0.0786\n",
      "Epoch 67/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5916 - pi_loss: 0.5130 - v_loss: 0.0785\n",
      "Epoch 68/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5901 - pi_loss: 0.5117 - v_loss: 0.0784\n",
      "Epoch 69/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5904 - pi_loss: 0.5122 - v_loss: 0.0782\n",
      "Epoch 70/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5897 - pi_loss: 0.5115 - v_loss: 0.0783\n",
      "Epoch 71/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5890 - pi_loss: 0.5109 - v_loss: 0.0781\n",
      "Epoch 72/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5896 - pi_loss: 0.5115 - v_loss: 0.0781\n",
      "Epoch 73/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5892 - pi_loss: 0.5110 - v_loss: 0.0782\n",
      "Epoch 74/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5892 - pi_loss: 0.5113 - v_loss: 0.0779\n",
      "Epoch 75/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5881 - pi_loss: 0.5106 - v_loss: 0.0775\n",
      "Epoch 76/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5885 - pi_loss: 0.5108 - v_loss: 0.0777\n",
      "Epoch 77/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5880 - pi_loss: 0.5102 - v_loss: 0.0778\n",
      "Epoch 78/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5881 - pi_loss: 0.5104 - v_loss: 0.0777\n",
      "Epoch 79/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5878 - pi_loss: 0.5103 - v_loss: 0.0775\n",
      "Epoch 80/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5870 - pi_loss: 0.5096 - v_loss: 0.0773\n",
      "Epoch 81/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5873 - pi_loss: 0.5099 - v_loss: 0.0774\n",
      "Epoch 82/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5870 - pi_loss: 0.5096 - v_loss: 0.0774\n",
      "Epoch 83/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5873 - pi_loss: 0.5098 - v_loss: 0.0775\n",
      "Epoch 84/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5864 - pi_loss: 0.5093 - v_loss: 0.0771\n",
      "Epoch 85/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5860 - pi_loss: 0.5089 - v_loss: 0.0771\n",
      "Epoch 86/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5858 - pi_loss: 0.5087 - v_loss: 0.0771\n",
      "Epoch 87/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5857 - pi_loss: 0.5085 - v_loss: 0.0772\n",
      "Epoch 88/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5855 - pi_loss: 0.5086 - v_loss: 0.0770\n",
      "Epoch 89/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5858 - pi_loss: 0.5090 - v_loss: 0.0769\n",
      "Epoch 90/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5845 - pi_loss: 0.5077 - v_loss: 0.0768\n",
      "Epoch 91/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5851 - pi_loss: 0.5085 - v_loss: 0.0766\n",
      "Epoch 92/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5852 - pi_loss: 0.5083 - v_loss: 0.0769\n",
      "Epoch 93/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5850 - pi_loss: 0.5082 - v_loss: 0.0768\n",
      "Epoch 94/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5844 - pi_loss: 0.5076 - v_loss: 0.0768\n",
      "Epoch 95/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5851 - pi_loss: 0.5084 - v_loss: 0.0767\n",
      "Epoch 96/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5842 - pi_loss: 0.5077 - v_loss: 0.0766\n",
      "Epoch 97/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5844 - pi_loss: 0.5076 - v_loss: 0.0767\n",
      "Epoch 98/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5840 - pi_loss: 0.5074 - v_loss: 0.0766\n",
      "Epoch 99/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5841 - pi_loss: 0.5077 - v_loss: 0.0764\n",
      "Epoch 100/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5833 - pi_loss: 0.5070 - v_loss: 0.0764\n",
      "Epoch 101/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5840 - pi_loss: 0.5074 - v_loss: 0.0766\n",
      "Epoch 102/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5835 - pi_loss: 0.5071 - v_loss: 0.0764\n",
      "Epoch 103/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5836 - pi_loss: 0.5070 - v_loss: 0.0766\n",
      "Epoch 104/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5828 - pi_loss: 0.5068 - v_loss: 0.0760\n",
      "Epoch 105/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5826 - pi_loss: 0.5063 - v_loss: 0.0763\n",
      "Epoch 106/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5832 - pi_loss: 0.5068 - v_loss: 0.0763\n",
      "Epoch 107/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5828 - pi_loss: 0.5066 - v_loss: 0.0762\n",
      "Epoch 108/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5829 - pi_loss: 0.5065 - v_loss: 0.0764\n",
      "Epoch 109/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5825 - pi_loss: 0.5064 - v_loss: 0.0761\n",
      "Epoch 110/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5827 - pi_loss: 0.5063 - v_loss: 0.0763\n",
      "Epoch 111/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5824 - pi_loss: 0.5064 - v_loss: 0.0759\n",
      "Epoch 112/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5819 - pi_loss: 0.5059 - v_loss: 0.0760\n",
      "Epoch 113/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5818 - pi_loss: 0.5056 - v_loss: 0.0762\n",
      "Epoch 114/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5813 - pi_loss: 0.5054 - v_loss: 0.0759\n",
      "Epoch 115/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5824 - pi_loss: 0.5065 - v_loss: 0.0759\n",
      "Epoch 116/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5812 - pi_loss: 0.5052 - v_loss: 0.0760\n",
      "Epoch 117/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5814 - pi_loss: 0.5052 - v_loss: 0.0762\n",
      "Epoch 118/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5818 - pi_loss: 0.5058 - v_loss: 0.0761\n",
      "Epoch 119/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5814 - pi_loss: 0.5055 - v_loss: 0.0759\n",
      "Epoch 120/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5814 - pi_loss: 0.5053 - v_loss: 0.0761\n",
      "Epoch 121/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5809 - pi_loss: 0.5052 - v_loss: 0.0757\n",
      "Epoch 122/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5807 - pi_loss: 0.5049 - v_loss: 0.0758\n",
      "Epoch 123/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5810 - pi_loss: 0.5050 - v_loss: 0.0759\n",
      "Epoch 124/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5806 - pi_loss: 0.5047 - v_loss: 0.0759\n",
      "Epoch 125/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5808 - pi_loss: 0.5051 - v_loss: 0.0757\n",
      "Epoch 126/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5807 - pi_loss: 0.5050 - v_loss: 0.0757\n",
      "Epoch 127/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5805 - pi_loss: 0.5046 - v_loss: 0.0759\n",
      "Epoch 128/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5802 - pi_loss: 0.5046 - v_loss: 0.0755\n",
      "Epoch 129/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5805 - pi_loss: 0.5047 - v_loss: 0.0758\n",
      "Epoch 130/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5802 - pi_loss: 0.5043 - v_loss: 0.0758\n",
      "Epoch 131/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5798 - pi_loss: 0.5042 - v_loss: 0.0756\n",
      "Epoch 132/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5803 - pi_loss: 0.5046 - v_loss: 0.0757\n",
      "Epoch 133/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5797 - pi_loss: 0.5042 - v_loss: 0.0754\n",
      "Epoch 134/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5795 - pi_loss: 0.5041 - v_loss: 0.0754\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5794 - pi_loss: 0.5038 - v_loss: 0.0756\n",
      "Epoch 136/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5798 - pi_loss: 0.5045 - v_loss: 0.0753\n",
      "Epoch 137/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5799 - pi_loss: 0.5042 - v_loss: 0.0757\n",
      "Epoch 138/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5794 - pi_loss: 0.5038 - v_loss: 0.0756\n",
      "Epoch 139/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5791 - pi_loss: 0.5036 - v_loss: 0.0755\n",
      "Epoch 140/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5791 - pi_loss: 0.5035 - v_loss: 0.0756\n",
      "Epoch 141/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5794 - pi_loss: 0.5039 - v_loss: 0.0755\n",
      "Epoch 142/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5791 - pi_loss: 0.5037 - v_loss: 0.0754\n",
      "Epoch 143/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5789 - pi_loss: 0.5036 - v_loss: 0.0753\n",
      "Epoch 144/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5789 - pi_loss: 0.5037 - v_loss: 0.0752\n",
      "Epoch 145/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5791 - pi_loss: 0.5037 - v_loss: 0.0754\n",
      "Epoch 146/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5790 - pi_loss: 0.5035 - v_loss: 0.0755\n",
      "Epoch 147/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5787 - pi_loss: 0.5035 - v_loss: 0.0752\n",
      "Epoch 148/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5787 - pi_loss: 0.5033 - v_loss: 0.0755\n",
      "Epoch 149/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5783 - pi_loss: 0.5032 - v_loss: 0.0751\n",
      "Epoch 150/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5785 - pi_loss: 0.5032 - v_loss: 0.0754\n",
      "Epoch 151/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5782 - pi_loss: 0.5031 - v_loss: 0.0751\n",
      "Epoch 152/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5779 - pi_loss: 0.5030 - v_loss: 0.0750\n",
      "Epoch 153/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5782 - pi_loss: 0.5030 - v_loss: 0.0752\n",
      "Epoch 154/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5777 - pi_loss: 0.5025 - v_loss: 0.0752\n",
      "Epoch 155/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5779 - pi_loss: 0.5025 - v_loss: 0.0753\n",
      "Epoch 156/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5777 - pi_loss: 0.5025 - v_loss: 0.0752\n",
      "Epoch 157/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5783 - pi_loss: 0.5030 - v_loss: 0.0754\n",
      "Epoch 158/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5779 - pi_loss: 0.5027 - v_loss: 0.0751\n",
      "Epoch 159/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5777 - pi_loss: 0.5026 - v_loss: 0.0751\n",
      "Epoch 160/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5775 - pi_loss: 0.5023 - v_loss: 0.0752\n",
      "Epoch 161/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5774 - pi_loss: 0.5023 - v_loss: 0.0751\n",
      "Epoch 162/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5775 - pi_loss: 0.5023 - v_loss: 0.0752\n",
      "Epoch 163/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5779 - pi_loss: 0.5029 - v_loss: 0.0750\n",
      "Epoch 164/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5773 - pi_loss: 0.5024 - v_loss: 0.0748\n",
      "Epoch 165/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5774 - pi_loss: 0.5026 - v_loss: 0.0749\n",
      "Epoch 166/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5774 - pi_loss: 0.5023 - v_loss: 0.0751\n",
      "Epoch 167/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5773 - pi_loss: 0.5024 - v_loss: 0.0750\n",
      "Epoch 168/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5774 - pi_loss: 0.5024 - v_loss: 0.0750\n",
      "Epoch 169/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5770 - pi_loss: 0.5020 - v_loss: 0.0751\n",
      "Epoch 170/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5779 - pi_loss: 0.5025 - v_loss: 0.0754\n",
      "Epoch 171/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5769 - pi_loss: 0.5020 - v_loss: 0.0749\n",
      "Epoch 172/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5769 - pi_loss: 0.5019 - v_loss: 0.0750\n",
      "Epoch 173/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5765 - pi_loss: 0.5016 - v_loss: 0.0749\n",
      "Epoch 174/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5769 - pi_loss: 0.5020 - v_loss: 0.0750\n",
      "Epoch 175/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5770 - pi_loss: 0.5021 - v_loss: 0.0749\n",
      "Epoch 176/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5770 - pi_loss: 0.5021 - v_loss: 0.0749\n",
      "Epoch 177/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5770 - pi_loss: 0.5022 - v_loss: 0.0748\n",
      "Epoch 178/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5769 - pi_loss: 0.5020 - v_loss: 0.0749\n",
      "Epoch 179/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5771 - pi_loss: 0.5022 - v_loss: 0.0749\n",
      "Epoch 180/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5766 - pi_loss: 0.5017 - v_loss: 0.0749\n",
      "Epoch 181/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5763 - pi_loss: 0.5015 - v_loss: 0.0748\n",
      "Epoch 182/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5768 - pi_loss: 0.5020 - v_loss: 0.0747\n",
      "Epoch 183/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5765 - pi_loss: 0.5018 - v_loss: 0.0747\n",
      "Epoch 184/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5764 - pi_loss: 0.5017 - v_loss: 0.0747\n",
      "Epoch 185/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5767 - pi_loss: 0.5020 - v_loss: 0.0747\n",
      "Epoch 186/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5763 - pi_loss: 0.5013 - v_loss: 0.0750\n",
      "Epoch 187/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5758 - pi_loss: 0.5011 - v_loss: 0.0747\n",
      "Epoch 188/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5762 - pi_loss: 0.5016 - v_loss: 0.0746\n",
      "Epoch 189/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5760 - pi_loss: 0.5012 - v_loss: 0.0748\n",
      "Epoch 190/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5763 - pi_loss: 0.5016 - v_loss: 0.0747\n",
      "Epoch 191/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5762 - pi_loss: 0.5013 - v_loss: 0.0750\n",
      "Epoch 192/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5759 - pi_loss: 0.5009 - v_loss: 0.0750\n",
      "Epoch 193/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5763 - pi_loss: 0.5014 - v_loss: 0.0748\n",
      "Epoch 194/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5757 - pi_loss: 0.5010 - v_loss: 0.0747\n",
      "Epoch 195/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5760 - pi_loss: 0.5013 - v_loss: 0.0747\n",
      "Epoch 196/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5760 - pi_loss: 0.5011 - v_loss: 0.0749\n",
      "Epoch 197/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5760 - pi_loss: 0.5012 - v_loss: 0.0748\n",
      "Epoch 198/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5756 - pi_loss: 0.5010 - v_loss: 0.0746\n",
      "Epoch 199/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5758 - pi_loss: 0.5012 - v_loss: 0.0747\n",
      "Epoch 200/200\n",
      "3097/3097 [==============================] - 25s 8ms/step - loss: 0.5756 - pi_loss: 0.5009 - v_loss: 0.0746\n",
      "==========TRAINING wl2=========\n",
      "Epoch 1/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 2.1463 - pi_loss: 1.4598 - v_loss: 0.1838\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.7067 - pi_loss: 1.0492 - v_loss: 0.1498\n",
      "Epoch 3/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.5987 - pi_loss: 0.9777 - v_loss: 0.1457\n",
      "Epoch 4/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.4883 - pi_loss: 0.9206 - v_loss: 0.1418\n",
      "Epoch 5/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.4099 - pi_loss: 0.8851 - v_loss: 0.1388\n",
      "Epoch 6/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.3570 - pi_loss: 0.8586 - v_loss: 0.1366\n",
      "Epoch 7/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.3214 - pi_loss: 0.8430 - v_loss: 0.1349\n",
      "Epoch 8/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.2963 - pi_loss: 0.8299 - v_loss: 0.1337\n",
      "Epoch 9/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.2770 - pi_loss: 0.8205 - v_loss: 0.1329\n",
      "Epoch 10/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.2581 - pi_loss: 0.8116 - v_loss: 0.1312\n",
      "Epoch 11/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.2447 - pi_loss: 0.8054 - v_loss: 0.1316\n",
      "Epoch 12/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.2314 - pi_loss: 0.7994 - v_loss: 0.1304\n",
      "Epoch 13/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.2192 - pi_loss: 0.7925 - v_loss: 0.1305\n",
      "Epoch 14/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.2109 - pi_loss: 0.7897 - v_loss: 0.1294\n",
      "Epoch 15/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1996 - pi_loss: 0.7835 - v_loss: 0.1285\n",
      "Epoch 16/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1940 - pi_loss: 0.7814 - v_loss: 0.1285\n",
      "Epoch 17/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1846 - pi_loss: 0.7761 - v_loss: 0.1278\n",
      "Epoch 18/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1800 - pi_loss: 0.7737 - v_loss: 0.1277\n",
      "Epoch 19/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1754 - pi_loss: 0.7717 - v_loss: 0.1273\n",
      "Epoch 20/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1698 - pi_loss: 0.7687 - v_loss: 0.1269\n",
      "Epoch 21/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1662 - pi_loss: 0.7669 - v_loss: 0.1263\n",
      "Epoch 22/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1597 - pi_loss: 0.7623 - v_loss: 0.1265\n",
      "Epoch 23/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1576 - pi_loss: 0.7621 - v_loss: 0.1258\n",
      "Epoch 24/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1529 - pi_loss: 0.7592 - v_loss: 0.1256\n",
      "Epoch 25/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1511 - pi_loss: 0.7585 - v_loss: 0.1260\n",
      "Epoch 26/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1474 - pi_loss: 0.7571 - v_loss: 0.1249\n",
      "Epoch 27/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1452 - pi_loss: 0.7556 - v_loss: 0.1248\n",
      "Epoch 28/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1422 - pi_loss: 0.7539 - v_loss: 0.1251\n",
      "Epoch 29/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1423 - pi_loss: 0.7546 - v_loss: 0.1252\n",
      "Epoch 30/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1373 - pi_loss: 0.7512 - v_loss: 0.1248\n",
      "Epoch 31/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1371 - pi_loss: 0.7511 - v_loss: 0.1252\n",
      "Epoch 32/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1345 - pi_loss: 0.7502 - v_loss: 0.1241\n",
      "Epoch 33/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1333 - pi_loss: 0.7497 - v_loss: 0.1240\n",
      "Epoch 34/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1324 - pi_loss: 0.7500 - v_loss: 0.1239\n",
      "Epoch 35/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1284 - pi_loss: 0.7472 - v_loss: 0.1237\n",
      "Epoch 36/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1281 - pi_loss: 0.7474 - v_loss: 0.1241\n",
      "Epoch 37/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1258 - pi_loss: 0.7461 - v_loss: 0.1241\n",
      "Epoch 38/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1252 - pi_loss: 0.7467 - v_loss: 0.1238\n",
      "Epoch 39/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1231 - pi_loss: 0.7450 - v_loss: 0.1236\n",
      "Epoch 40/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1210 - pi_loss: 0.7439 - v_loss: 0.1233\n",
      "Epoch 41/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1196 - pi_loss: 0.7426 - v_loss: 0.1237\n",
      "Epoch 42/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1183 - pi_loss: 0.7431 - v_loss: 0.1228\n",
      "Epoch 43/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1154 - pi_loss: 0.7409 - v_loss: 0.1226\n",
      "Epoch 44/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1147 - pi_loss: 0.7406 - v_loss: 0.1226\n",
      "Epoch 45/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1160 - pi_loss: 0.7418 - v_loss: 0.1232\n",
      "Epoch 46/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1133 - pi_loss: 0.7392 - v_loss: 0.1228\n",
      "Epoch 47/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1123 - pi_loss: 0.7394 - v_loss: 0.1225\n",
      "Epoch 48/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1122 - pi_loss: 0.7394 - v_loss: 0.1226\n",
      "Epoch 49/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1096 - pi_loss: 0.7383 - v_loss: 0.1219\n",
      "Epoch 50/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1096 - pi_loss: 0.7383 - v_loss: 0.1220\n",
      "Epoch 51/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1086 - pi_loss: 0.7384 - v_loss: 0.1224\n",
      "Epoch 52/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1069 - pi_loss: 0.7365 - v_loss: 0.1222\n",
      "Epoch 53/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.1056 - pi_loss: 0.7362 - v_loss: 0.1220\n",
      "Epoch 54/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.1072 - pi_loss: 0.7375 - v_loss: 0.1222\n",
      "Epoch 55/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.1052 - pi_loss: 0.7368 - v_loss: 0.1220\n",
      "Epoch 56/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1038 - pi_loss: 0.7357 - v_loss: 0.1216\n",
      "Epoch 57/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.1038 - pi_loss: 0.7358 - v_loss: 0.1214\n",
      "Epoch 58/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1029 - pi_loss: 0.7355 - v_loss: 0.1214\n",
      "Epoch 59/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1017 - pi_loss: 0.7340 - v_loss: 0.1224\n",
      "Epoch 60/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.1040 - pi_loss: 0.7372 - v_loss: 0.1214\n",
      "Epoch 61/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1011 - pi_loss: 0.7340 - v_loss: 0.1221\n",
      "Epoch 62/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1004 - pi_loss: 0.7340 - v_loss: 0.1219\n",
      "Epoch 63/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.1006 - pi_loss: 0.7343 - v_loss: 0.1216\n",
      "Epoch 64/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0989 - pi_loss: 0.7335 - v_loss: 0.1217\n",
      "Epoch 65/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0992 - pi_loss: 0.7330 - v_loss: 0.1218\n",
      "Epoch 66/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0983 - pi_loss: 0.7327 - v_loss: 0.1215\n",
      "Epoch 67/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0967 - pi_loss: 0.7326 - v_loss: 0.1213\n",
      "Epoch 68/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0973 - pi_loss: 0.7327 - v_loss: 0.1209\n",
      "Epoch 69/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0961 - pi_loss: 0.7318 - v_loss: 0.1213\n",
      "Epoch 70/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0981 - pi_loss: 0.7335 - v_loss: 0.1217\n",
      "Epoch 71/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0953 - pi_loss: 0.7320 - v_loss: 0.1212\n",
      "Epoch 72/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0951 - pi_loss: 0.7318 - v_loss: 0.1214\n",
      "Epoch 73/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0950 - pi_loss: 0.7323 - v_loss: 0.1206\n",
      "Epoch 74/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0938 - pi_loss: 0.7312 - v_loss: 0.1213\n",
      "Epoch 75/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0915 - pi_loss: 0.7301 - v_loss: 0.1207\n",
      "Epoch 76/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0926 - pi_loss: 0.7306 - v_loss: 0.1210\n",
      "Epoch 77/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0919 - pi_loss: 0.7305 - v_loss: 0.1209\n",
      "Epoch 78/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0923 - pi_loss: 0.7302 - v_loss: 0.1212\n",
      "Epoch 79/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0910 - pi_loss: 0.7298 - v_loss: 0.1214\n",
      "Epoch 80/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0901 - pi_loss: 0.7296 - v_loss: 0.1212\n",
      "Epoch 81/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0891 - pi_loss: 0.7293 - v_loss: 0.1205\n",
      "Epoch 82/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0899 - pi_loss: 0.7297 - v_loss: 0.1207\n",
      "Epoch 83/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0897 - pi_loss: 0.7300 - v_loss: 0.1208\n",
      "Epoch 84/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0888 - pi_loss: 0.7285 - v_loss: 0.1212\n",
      "Epoch 85/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0873 - pi_loss: 0.7283 - v_loss: 0.1208\n",
      "Epoch 86/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0862 - pi_loss: 0.7275 - v_loss: 0.1207\n",
      "Epoch 87/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0881 - pi_loss: 0.7295 - v_loss: 0.1207\n",
      "Epoch 88/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0876 - pi_loss: 0.7288 - v_loss: 0.1213\n",
      "Epoch 89/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0841 - pi_loss: 0.7265 - v_loss: 0.1201\n",
      "Epoch 90/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0870 - pi_loss: 0.7285 - v_loss: 0.1212\n",
      "Epoch 91/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0853 - pi_loss: 0.7273 - v_loss: 0.1207\n",
      "Epoch 92/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0841 - pi_loss: 0.7265 - v_loss: 0.1205\n",
      "Epoch 93/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0846 - pi_loss: 0.7274 - v_loss: 0.1205\n",
      "Epoch 94/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0830 - pi_loss: 0.7263 - v_loss: 0.1208\n",
      "Epoch 95/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0832 - pi_loss: 0.7265 - v_loss: 0.1204\n",
      "Epoch 96/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0829 - pi_loss: 0.7268 - v_loss: 0.1199\n",
      "Epoch 97/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0825 - pi_loss: 0.7263 - v_loss: 0.1204\n",
      "Epoch 98/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0821 - pi_loss: 0.7263 - v_loss: 0.1204\n",
      "Epoch 99/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0815 - pi_loss: 0.7255 - v_loss: 0.1203\n",
      "Epoch 100/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0814 - pi_loss: 0.7255 - v_loss: 0.1207\n",
      "Epoch 101/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0825 - pi_loss: 0.7266 - v_loss: 0.1205\n",
      "Epoch 102/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0787 - pi_loss: 0.7240 - v_loss: 0.1199\n",
      "Epoch 103/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0804 - pi_loss: 0.7261 - v_loss: 0.1198\n",
      "Epoch 104/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0799 - pi_loss: 0.7260 - v_loss: 0.1195\n",
      "Epoch 105/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0799 - pi_loss: 0.7251 - v_loss: 0.1203\n",
      "Epoch 106/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0794 - pi_loss: 0.7256 - v_loss: 0.1198\n",
      "Epoch 107/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0783 - pi_loss: 0.7247 - v_loss: 0.1198\n",
      "Epoch 108/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0785 - pi_loss: 0.7245 - v_loss: 0.1204\n",
      "Epoch 109/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0769 - pi_loss: 0.7237 - v_loss: 0.1200\n",
      "Epoch 110/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0768 - pi_loss: 0.7237 - v_loss: 0.1204\n",
      "Epoch 111/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0775 - pi_loss: 0.7245 - v_loss: 0.1196\n",
      "Epoch 112/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0777 - pi_loss: 0.7238 - v_loss: 0.1200\n",
      "Epoch 113/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0777 - pi_loss: 0.7237 - v_loss: 0.1207\n",
      "Epoch 114/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0777 - pi_loss: 0.7251 - v_loss: 0.1196\n",
      "Epoch 115/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0761 - pi_loss: 0.7239 - v_loss: 0.1192\n",
      "Epoch 116/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0762 - pi_loss: 0.7235 - v_loss: 0.1199\n",
      "Epoch 117/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0768 - pi_loss: 0.7245 - v_loss: 0.1196\n",
      "Epoch 118/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0747 - pi_loss: 0.7225 - v_loss: 0.1196\n",
      "Epoch 119/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0758 - pi_loss: 0.7233 - v_loss: 0.1200\n",
      "Epoch 120/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0763 - pi_loss: 0.7239 - v_loss: 0.1198\n",
      "Epoch 121/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0755 - pi_loss: 0.7232 - v_loss: 0.1198\n",
      "Epoch 122/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0760 - pi_loss: 0.7232 - v_loss: 0.1202\n",
      "Epoch 123/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0755 - pi_loss: 0.7232 - v_loss: 0.1199\n",
      "Epoch 124/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0736 - pi_loss: 0.7223 - v_loss: 0.1198\n",
      "Epoch 125/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0755 - pi_loss: 0.7233 - v_loss: 0.1197\n",
      "Epoch 126/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0750 - pi_loss: 0.7236 - v_loss: 0.1194\n",
      "Epoch 127/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0733 - pi_loss: 0.7211 - v_loss: 0.1198\n",
      "Epoch 128/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0731 - pi_loss: 0.7216 - v_loss: 0.1198\n",
      "Epoch 129/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0737 - pi_loss: 0.7217 - v_loss: 0.1201\n",
      "Epoch 130/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0739 - pi_loss: 0.7230 - v_loss: 0.1193\n",
      "Epoch 131/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0712 - pi_loss: 0.7210 - v_loss: 0.1193\n",
      "Epoch 132/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0717 - pi_loss: 0.7215 - v_loss: 0.1197\n",
      "Epoch 133/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0719 - pi_loss: 0.7220 - v_loss: 0.1194\n",
      "Epoch 134/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0728 - pi_loss: 0.7229 - v_loss: 0.1195\n",
      "Epoch 135/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0710 - pi_loss: 0.7207 - v_loss: 0.1199\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0713 - pi_loss: 0.7212 - v_loss: 0.1199\n",
      "Epoch 137/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0718 - pi_loss: 0.7216 - v_loss: 0.1197\n",
      "Epoch 138/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0713 - pi_loss: 0.7211 - v_loss: 0.1200\n",
      "Epoch 139/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0694 - pi_loss: 0.7197 - v_loss: 0.1194\n",
      "Epoch 140/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0704 - pi_loss: 0.7217 - v_loss: 0.1193\n",
      "Epoch 141/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0710 - pi_loss: 0.7219 - v_loss: 0.1192\n",
      "Epoch 142/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0708 - pi_loss: 0.7217 - v_loss: 0.1191\n",
      "Epoch 143/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0696 - pi_loss: 0.7207 - v_loss: 0.1191\n",
      "Epoch 144/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0701 - pi_loss: 0.7207 - v_loss: 0.1195\n",
      "Epoch 145/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0699 - pi_loss: 0.7205 - v_loss: 0.1193\n",
      "Epoch 146/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0700 - pi_loss: 0.7204 - v_loss: 0.1194\n",
      "Epoch 147/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0715 - pi_loss: 0.7219 - v_loss: 0.1201\n",
      "Epoch 148/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0690 - pi_loss: 0.7203 - v_loss: 0.1196\n",
      "Epoch 149/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0693 - pi_loss: 0.7208 - v_loss: 0.1193\n",
      "Epoch 150/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0685 - pi_loss: 0.7196 - v_loss: 0.1196\n",
      "Epoch 151/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0684 - pi_loss: 0.7208 - v_loss: 0.1188\n",
      "Epoch 152/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0697 - pi_loss: 0.7216 - v_loss: 0.1196\n",
      "Epoch 153/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0670 - pi_loss: 0.7187 - v_loss: 0.1197\n",
      "Epoch 154/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0695 - pi_loss: 0.7217 - v_loss: 0.1193\n",
      "Epoch 155/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0695 - pi_loss: 0.7217 - v_loss: 0.1191\n",
      "Epoch 156/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0705 - pi_loss: 0.7224 - v_loss: 0.1198\n",
      "Epoch 157/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0676 - pi_loss: 0.7205 - v_loss: 0.1191\n",
      "Epoch 158/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0679 - pi_loss: 0.7205 - v_loss: 0.1195\n",
      "Epoch 159/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0685 - pi_loss: 0.7211 - v_loss: 0.1189\n",
      "Epoch 160/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0677 - pi_loss: 0.7202 - v_loss: 0.1193\n",
      "Epoch 161/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0685 - pi_loss: 0.7210 - v_loss: 0.1194\n",
      "Epoch 162/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0661 - pi_loss: 0.7192 - v_loss: 0.1194\n",
      "Epoch 163/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0683 - pi_loss: 0.7211 - v_loss: 0.1191\n",
      "Epoch 164/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0657 - pi_loss: 0.7192 - v_loss: 0.1187\n",
      "Epoch 165/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0673 - pi_loss: 0.7197 - v_loss: 0.1198\n",
      "Epoch 166/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0661 - pi_loss: 0.7196 - v_loss: 0.1189\n",
      "Epoch 167/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0661 - pi_loss: 0.7196 - v_loss: 0.1190\n",
      "Epoch 168/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0673 - pi_loss: 0.7199 - v_loss: 0.1195\n",
      "Epoch 169/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0666 - pi_loss: 0.7200 - v_loss: 0.1189\n",
      "Epoch 170/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0670 - pi_loss: 0.7202 - v_loss: 0.1193\n",
      "Epoch 171/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0662 - pi_loss: 0.7194 - v_loss: 0.1193\n",
      "Epoch 172/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0654 - pi_loss: 0.7182 - v_loss: 0.1193\n",
      "Epoch 173/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0652 - pi_loss: 0.7192 - v_loss: 0.1187\n",
      "Epoch 174/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0663 - pi_loss: 0.7196 - v_loss: 0.1196\n",
      "Epoch 175/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0661 - pi_loss: 0.7194 - v_loss: 0.1193\n",
      "Epoch 176/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0663 - pi_loss: 0.7200 - v_loss: 0.1189\n",
      "Epoch 177/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0664 - pi_loss: 0.7200 - v_loss: 0.1190\n",
      "Epoch 178/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0648 - pi_loss: 0.7187 - v_loss: 0.1187\n",
      "Epoch 179/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0653 - pi_loss: 0.7187 - v_loss: 0.1189\n",
      "Epoch 180/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0651 - pi_loss: 0.7185 - v_loss: 0.1193\n",
      "Epoch 181/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0657 - pi_loss: 0.7193 - v_loss: 0.1190\n",
      "Epoch 182/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0649 - pi_loss: 0.7189 - v_loss: 0.1197\n",
      "Epoch 183/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0639 - pi_loss: 0.7185 - v_loss: 0.1194\n",
      "Epoch 184/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0657 - pi_loss: 0.7197 - v_loss: 0.1195\n",
      "Epoch 185/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0652 - pi_loss: 0.7197 - v_loss: 0.1189\n",
      "Epoch 186/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0647 - pi_loss: 0.7188 - v_loss: 0.1194\n",
      "Epoch 187/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0641 - pi_loss: 0.7183 - v_loss: 0.1189\n",
      "Epoch 188/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0641 - pi_loss: 0.7184 - v_loss: 0.1193\n",
      "Epoch 189/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0656 - pi_loss: 0.7201 - v_loss: 0.1189\n",
      "Epoch 190/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0624 - pi_loss: 0.7167 - v_loss: 0.1192\n",
      "Epoch 191/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0636 - pi_loss: 0.7181 - v_loss: 0.1192\n",
      "Epoch 192/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0648 - pi_loss: 0.7191 - v_loss: 0.1191\n",
      "Epoch 193/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0633 - pi_loss: 0.7178 - v_loss: 0.1190\n",
      "Epoch 194/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0647 - pi_loss: 0.7190 - v_loss: 0.1192\n",
      "Epoch 195/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0641 - pi_loss: 0.7184 - v_loss: 0.1189\n",
      "Epoch 196/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0636 - pi_loss: 0.7178 - v_loss: 0.1193\n",
      "Epoch 197/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0629 - pi_loss: 0.7183 - v_loss: 0.1189\n",
      "Epoch 198/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0647 - pi_loss: 0.7186 - v_loss: 0.1195\n",
      "Epoch 199/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 1.0638 - pi_loss: 0.7182 - v_loss: 0.1194\n",
      "Epoch 200/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0622 - pi_loss: 0.7176 - v_loss: 0.1185\n",
      "==========TRAINING convhead=========\n",
      "Epoch 1/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.6138 - pi_loss: 1.4397 - v_loss: 0.1742\n",
      "Epoch 2/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 1.0681 - pi_loss: 0.9322 - v_loss: 0.1359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.9650 - pi_loss: 0.8373 - v_loss: 0.1277\n",
      "Epoch 4/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.9013 - pi_loss: 0.7787 - v_loss: 0.1226\n",
      "Epoch 5/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.8511 - pi_loss: 0.7325 - v_loss: 0.1186\n",
      "Epoch 6/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.8165 - pi_loss: 0.7017 - v_loss: 0.1148\n",
      "Epoch 7/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.7851 - pi_loss: 0.6740 - v_loss: 0.1111\n",
      "Epoch 8/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.7588 - pi_loss: 0.6509 - v_loss: 0.1079\n",
      "Epoch 9/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.7409 - pi_loss: 0.6357 - v_loss: 0.1051\n",
      "Epoch 10/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.7239 - pi_loss: 0.6212 - v_loss: 0.1027\n",
      "Epoch 11/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.7099 - pi_loss: 0.6090 - v_loss: 0.1010\n",
      "Epoch 12/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6992 - pi_loss: 0.6005 - v_loss: 0.0986\n",
      "Epoch 13/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6894 - pi_loss: 0.5924 - v_loss: 0.0969\n",
      "Epoch 14/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6806 - pi_loss: 0.5850 - v_loss: 0.0956\n",
      "Epoch 15/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6728 - pi_loss: 0.5785 - v_loss: 0.0942\n",
      "Epoch 16/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6672 - pi_loss: 0.5744 - v_loss: 0.0927\n",
      "Epoch 17/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6615 - pi_loss: 0.5693 - v_loss: 0.0922\n",
      "Epoch 18/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6566 - pi_loss: 0.5658 - v_loss: 0.0909\n",
      "Epoch 19/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6520 - pi_loss: 0.5619 - v_loss: 0.0900\n",
      "Epoch 20/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6493 - pi_loss: 0.5600 - v_loss: 0.0893\n",
      "Epoch 21/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6449 - pi_loss: 0.5562 - v_loss: 0.0887\n",
      "Epoch 22/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6408 - pi_loss: 0.5529 - v_loss: 0.0879\n",
      "Epoch 23/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6369 - pi_loss: 0.5500 - v_loss: 0.0868\n",
      "Epoch 24/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6360 - pi_loss: 0.5494 - v_loss: 0.0866\n",
      "Epoch 25/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6324 - pi_loss: 0.5466 - v_loss: 0.0859\n",
      "Epoch 26/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6307 - pi_loss: 0.5449 - v_loss: 0.0858\n",
      "Epoch 27/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6278 - pi_loss: 0.5429 - v_loss: 0.0849\n",
      "Epoch 28/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6269 - pi_loss: 0.5422 - v_loss: 0.0847\n",
      "Epoch 29/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6244 - pi_loss: 0.5402 - v_loss: 0.0842\n",
      "Epoch 30/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6228 - pi_loss: 0.5389 - v_loss: 0.0839\n",
      "Epoch 31/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6202 - pi_loss: 0.5366 - v_loss: 0.0836\n",
      "Epoch 32/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6190 - pi_loss: 0.5359 - v_loss: 0.0831\n",
      "Epoch 33/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6183 - pi_loss: 0.5353 - v_loss: 0.0830\n",
      "Epoch 34/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6160 - pi_loss: 0.5333 - v_loss: 0.0827\n",
      "Epoch 35/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6157 - pi_loss: 0.5332 - v_loss: 0.0824\n",
      "Epoch 36/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6138 - pi_loss: 0.5319 - v_loss: 0.0819\n",
      "Epoch 37/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6124 - pi_loss: 0.5307 - v_loss: 0.0817\n",
      "Epoch 38/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6109 - pi_loss: 0.5293 - v_loss: 0.0816\n",
      "Epoch 39/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6113 - pi_loss: 0.5300 - v_loss: 0.0813\n",
      "Epoch 40/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6095 - pi_loss: 0.5286 - v_loss: 0.0809\n",
      "Epoch 41/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6090 - pi_loss: 0.5278 - v_loss: 0.0812\n",
      "Epoch 42/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6077 - pi_loss: 0.5271 - v_loss: 0.0806\n",
      "Epoch 43/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6076 - pi_loss: 0.5269 - v_loss: 0.0807\n",
      "Epoch 44/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6051 - pi_loss: 0.5251 - v_loss: 0.0801\n",
      "Epoch 45/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6055 - pi_loss: 0.5253 - v_loss: 0.0802\n",
      "Epoch 46/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6044 - pi_loss: 0.5245 - v_loss: 0.0799\n",
      "Epoch 47/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6039 - pi_loss: 0.5240 - v_loss: 0.0799\n",
      "Epoch 48/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6038 - pi_loss: 0.5243 - v_loss: 0.0796\n",
      "Epoch 49/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6022 - pi_loss: 0.5226 - v_loss: 0.0796\n",
      "Epoch 50/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6014 - pi_loss: 0.5218 - v_loss: 0.0796\n",
      "Epoch 51/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6013 - pi_loss: 0.5220 - v_loss: 0.0793\n",
      "Epoch 52/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6022 - pi_loss: 0.5229 - v_loss: 0.0793\n",
      "Epoch 53/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5988 - pi_loss: 0.5199 - v_loss: 0.0790\n",
      "Epoch 54/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.6003 - pi_loss: 0.5212 - v_loss: 0.0791\n",
      "Epoch 55/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5989 - pi_loss: 0.5197 - v_loss: 0.0792\n",
      "Epoch 56/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5985 - pi_loss: 0.5199 - v_loss: 0.0786\n",
      "Epoch 57/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5984 - pi_loss: 0.5198 - v_loss: 0.0786\n",
      "Epoch 58/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5976 - pi_loss: 0.5190 - v_loss: 0.0786\n",
      "Epoch 59/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5962 - pi_loss: 0.5180 - v_loss: 0.0782\n",
      "Epoch 60/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5967 - pi_loss: 0.5186 - v_loss: 0.0781\n",
      "Epoch 61/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5954 - pi_loss: 0.5173 - v_loss: 0.0780\n",
      "Epoch 62/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5959 - pi_loss: 0.5177 - v_loss: 0.0781\n",
      "Epoch 63/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5949 - pi_loss: 0.5170 - v_loss: 0.0779\n",
      "Epoch 64/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5957 - pi_loss: 0.5177 - v_loss: 0.0780\n",
      "Epoch 65/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5947 - pi_loss: 0.5168 - v_loss: 0.0779\n",
      "Epoch 66/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5939 - pi_loss: 0.5164 - v_loss: 0.0775\n",
      "Epoch 67/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5930 - pi_loss: 0.5156 - v_loss: 0.0774\n",
      "Epoch 68/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5933 - pi_loss: 0.5159 - v_loss: 0.0774\n",
      "Epoch 69/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5925 - pi_loss: 0.5153 - v_loss: 0.0772\n",
      "Epoch 70/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5933 - pi_loss: 0.5159 - v_loss: 0.0774\n",
      "Epoch 71/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5922 - pi_loss: 0.5147 - v_loss: 0.0774\n",
      "Epoch 72/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5921 - pi_loss: 0.5150 - v_loss: 0.0770\n",
      "Epoch 73/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5920 - pi_loss: 0.5146 - v_loss: 0.0774\n",
      "Epoch 74/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5906 - pi_loss: 0.5137 - v_loss: 0.0769\n",
      "Epoch 75/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5911 - pi_loss: 0.5142 - v_loss: 0.0769\n",
      "Epoch 76/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5908 - pi_loss: 0.5138 - v_loss: 0.0770\n",
      "Epoch 77/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5901 - pi_loss: 0.5131 - v_loss: 0.0770\n",
      "Epoch 78/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5905 - pi_loss: 0.5135 - v_loss: 0.0770\n",
      "Epoch 79/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5894 - pi_loss: 0.5126 - v_loss: 0.0768\n",
      "Epoch 80/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5900 - pi_loss: 0.5132 - v_loss: 0.0768\n",
      "Epoch 81/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5894 - pi_loss: 0.5126 - v_loss: 0.0767\n",
      "Epoch 82/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5889 - pi_loss: 0.5124 - v_loss: 0.0764\n",
      "Epoch 83/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5891 - pi_loss: 0.5127 - v_loss: 0.0764\n",
      "Epoch 84/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5881 - pi_loss: 0.5118 - v_loss: 0.0763\n",
      "Epoch 85/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5882 - pi_loss: 0.5116 - v_loss: 0.0765\n",
      "Epoch 86/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5880 - pi_loss: 0.5115 - v_loss: 0.0765\n",
      "Epoch 87/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5882 - pi_loss: 0.5118 - v_loss: 0.0763\n",
      "Epoch 88/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5872 - pi_loss: 0.5111 - v_loss: 0.0762\n",
      "Epoch 89/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5879 - pi_loss: 0.5117 - v_loss: 0.0762\n",
      "Epoch 90/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5869 - pi_loss: 0.5109 - v_loss: 0.0760\n",
      "Epoch 91/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5868 - pi_loss: 0.5109 - v_loss: 0.0759\n",
      "Epoch 92/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5866 - pi_loss: 0.5104 - v_loss: 0.0762\n",
      "Epoch 93/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5870 - pi_loss: 0.5110 - v_loss: 0.0761\n",
      "Epoch 94/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5855 - pi_loss: 0.5097 - v_loss: 0.0758\n",
      "Epoch 95/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5862 - pi_loss: 0.5103 - v_loss: 0.0759\n",
      "Epoch 96/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5855 - pi_loss: 0.5099 - v_loss: 0.0756\n",
      "Epoch 97/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5864 - pi_loss: 0.5105 - v_loss: 0.0759\n",
      "Epoch 98/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5858 - pi_loss: 0.5099 - v_loss: 0.0759\n",
      "Epoch 99/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5859 - pi_loss: 0.5103 - v_loss: 0.0756\n",
      "Epoch 100/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5853 - pi_loss: 0.5097 - v_loss: 0.0757\n",
      "Epoch 101/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5856 - pi_loss: 0.5099 - v_loss: 0.0757\n",
      "Epoch 102/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5846 - pi_loss: 0.5092 - v_loss: 0.0754\n",
      "Epoch 103/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5849 - pi_loss: 0.5097 - v_loss: 0.0753\n",
      "Epoch 104/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5848 - pi_loss: 0.5093 - v_loss: 0.0755\n",
      "Epoch 105/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5837 - pi_loss: 0.5084 - v_loss: 0.0753\n",
      "Epoch 106/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5838 - pi_loss: 0.5084 - v_loss: 0.0754\n",
      "Epoch 107/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5839 - pi_loss: 0.5086 - v_loss: 0.0753\n",
      "Epoch 108/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5843 - pi_loss: 0.5090 - v_loss: 0.0753\n",
      "Epoch 109/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5843 - pi_loss: 0.5087 - v_loss: 0.0756\n",
      "Epoch 110/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5829 - pi_loss: 0.5077 - v_loss: 0.0752\n",
      "Epoch 111/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5836 - pi_loss: 0.5084 - v_loss: 0.0753\n",
      "Epoch 112/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5828 - pi_loss: 0.5077 - v_loss: 0.0751\n",
      "Epoch 113/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5839 - pi_loss: 0.5087 - v_loss: 0.0752\n",
      "Epoch 114/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5830 - pi_loss: 0.5077 - v_loss: 0.0753\n",
      "Epoch 115/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5832 - pi_loss: 0.5082 - v_loss: 0.0750\n",
      "Epoch 116/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5828 - pi_loss: 0.5076 - v_loss: 0.0751\n",
      "Epoch 117/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5824 - pi_loss: 0.5073 - v_loss: 0.0751\n",
      "Epoch 118/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5827 - pi_loss: 0.5075 - v_loss: 0.0752\n",
      "Epoch 119/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5821 - pi_loss: 0.5069 - v_loss: 0.0752\n",
      "Epoch 120/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5827 - pi_loss: 0.5074 - v_loss: 0.0753\n",
      "Epoch 121/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5818 - pi_loss: 0.5066 - v_loss: 0.0751\n",
      "Epoch 122/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5818 - pi_loss: 0.5070 - v_loss: 0.0748\n",
      "Epoch 123/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5823 - pi_loss: 0.5072 - v_loss: 0.0751\n",
      "Epoch 124/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5821 - pi_loss: 0.5071 - v_loss: 0.0750\n",
      "Epoch 125/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5819 - pi_loss: 0.5067 - v_loss: 0.0751\n",
      "Epoch 126/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5806 - pi_loss: 0.5058 - v_loss: 0.0748\n",
      "Epoch 127/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5822 - pi_loss: 0.5070 - v_loss: 0.0752\n",
      "Epoch 128/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5816 - pi_loss: 0.5066 - v_loss: 0.0749\n",
      "Epoch 129/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5812 - pi_loss: 0.5065 - v_loss: 0.0747\n",
      "Epoch 130/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5804 - pi_loss: 0.5056 - v_loss: 0.0748\n",
      "Epoch 131/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5808 - pi_loss: 0.5059 - v_loss: 0.0749\n",
      "Epoch 132/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5813 - pi_loss: 0.5067 - v_loss: 0.0746\n",
      "Epoch 133/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5807 - pi_loss: 0.5061 - v_loss: 0.0746\n",
      "Epoch 134/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5801 - pi_loss: 0.5052 - v_loss: 0.0749\n",
      "Epoch 135/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5817 - pi_loss: 0.5069 - v_loss: 0.0749\n",
      "Epoch 136/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5797 - pi_loss: 0.5048 - v_loss: 0.0749\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5809 - pi_loss: 0.5061 - v_loss: 0.0747\n",
      "Epoch 138/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5810 - pi_loss: 0.5063 - v_loss: 0.0747\n",
      "Epoch 139/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5798 - pi_loss: 0.5055 - v_loss: 0.0744\n",
      "Epoch 140/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5804 - pi_loss: 0.5057 - v_loss: 0.0748\n",
      "Epoch 141/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5794 - pi_loss: 0.5049 - v_loss: 0.0745\n",
      "Epoch 142/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5806 - pi_loss: 0.5057 - v_loss: 0.0749\n",
      "Epoch 143/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5790 - pi_loss: 0.5047 - v_loss: 0.0743\n",
      "Epoch 144/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5796 - pi_loss: 0.5052 - v_loss: 0.0744\n",
      "Epoch 145/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5799 - pi_loss: 0.5054 - v_loss: 0.0745\n",
      "Epoch 146/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5797 - pi_loss: 0.5051 - v_loss: 0.0746\n",
      "Epoch 147/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5794 - pi_loss: 0.5050 - v_loss: 0.0745\n",
      "Epoch 148/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5802 - pi_loss: 0.5053 - v_loss: 0.0749\n",
      "Epoch 149/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5788 - pi_loss: 0.5045 - v_loss: 0.0743\n",
      "Epoch 150/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5792 - pi_loss: 0.5045 - v_loss: 0.0747\n",
      "Epoch 151/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5790 - pi_loss: 0.5046 - v_loss: 0.0744\n",
      "Epoch 152/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5789 - pi_loss: 0.5045 - v_loss: 0.0744\n",
      "Epoch 153/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5792 - pi_loss: 0.5047 - v_loss: 0.0745\n",
      "Epoch 154/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5790 - pi_loss: 0.5048 - v_loss: 0.0742\n",
      "Epoch 155/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5785 - pi_loss: 0.5040 - v_loss: 0.0745\n",
      "Epoch 156/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5781 - pi_loss: 0.5037 - v_loss: 0.0744\n",
      "Epoch 157/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5788 - pi_loss: 0.5045 - v_loss: 0.0743\n",
      "Epoch 158/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5791 - pi_loss: 0.5047 - v_loss: 0.0744\n",
      "Epoch 159/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5785 - pi_loss: 0.5041 - v_loss: 0.0744\n",
      "Epoch 160/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5783 - pi_loss: 0.5041 - v_loss: 0.0742\n",
      "Epoch 161/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5786 - pi_loss: 0.5044 - v_loss: 0.0742\n",
      "Epoch 162/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5784 - pi_loss: 0.5040 - v_loss: 0.0743\n",
      "Epoch 163/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5781 - pi_loss: 0.5040 - v_loss: 0.0740\n",
      "Epoch 164/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5780 - pi_loss: 0.5039 - v_loss: 0.0742\n",
      "Epoch 165/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5784 - pi_loss: 0.5041 - v_loss: 0.0742\n",
      "Epoch 166/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5778 - pi_loss: 0.5034 - v_loss: 0.0744\n",
      "Epoch 167/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5779 - pi_loss: 0.5036 - v_loss: 0.0743\n",
      "Epoch 168/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5776 - pi_loss: 0.5033 - v_loss: 0.0743\n",
      "Epoch 169/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5781 - pi_loss: 0.5038 - v_loss: 0.0744\n",
      "Epoch 170/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5776 - pi_loss: 0.5031 - v_loss: 0.0744\n",
      "Epoch 171/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5779 - pi_loss: 0.5038 - v_loss: 0.0741\n",
      "Epoch 172/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5779 - pi_loss: 0.5035 - v_loss: 0.0744\n",
      "Epoch 173/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5771 - pi_loss: 0.5032 - v_loss: 0.0740\n",
      "Epoch 174/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5774 - pi_loss: 0.5032 - v_loss: 0.0742\n",
      "Epoch 175/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5772 - pi_loss: 0.5031 - v_loss: 0.0741\n",
      "Epoch 176/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5776 - pi_loss: 0.5035 - v_loss: 0.0740\n",
      "Epoch 177/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5774 - pi_loss: 0.5033 - v_loss: 0.0741\n",
      "Epoch 178/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5783 - pi_loss: 0.5033 - v_loss: 0.0750\n",
      "Epoch 179/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5772 - pi_loss: 0.5032 - v_loss: 0.0740\n",
      "Epoch 180/200\n",
      "3097/3097 [==============================] - 28s 9ms/step - loss: 0.5770 - pi_loss: 0.5030 - v_loss: 0.0739\n",
      "Epoch 181/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5766 - pi_loss: 0.5027 - v_loss: 0.0739\n",
      "Epoch 182/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5778 - pi_loss: 0.5036 - v_loss: 0.0742\n",
      "Epoch 183/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5767 - pi_loss: 0.5027 - v_loss: 0.0739\n",
      "Epoch 184/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5767 - pi_loss: 0.5026 - v_loss: 0.0741\n",
      "Epoch 185/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5773 - pi_loss: 0.5032 - v_loss: 0.0741\n",
      "Epoch 186/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5765 - pi_loss: 0.5026 - v_loss: 0.0739\n",
      "Epoch 187/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5770 - pi_loss: 0.5031 - v_loss: 0.0740\n",
      "Epoch 188/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5769 - pi_loss: 0.5030 - v_loss: 0.0739\n",
      "Epoch 189/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5771 - pi_loss: 0.5025 - v_loss: 0.0746\n",
      "Epoch 190/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5771 - pi_loss: 0.5030 - v_loss: 0.0740\n",
      "Epoch 191/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5766 - pi_loss: 0.5028 - v_loss: 0.0738\n",
      "Epoch 192/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5765 - pi_loss: 0.5026 - v_loss: 0.0739\n",
      "Epoch 193/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5756 - pi_loss: 0.5019 - v_loss: 0.0737\n",
      "Epoch 194/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5769 - pi_loss: 0.5029 - v_loss: 0.0741\n",
      "Epoch 195/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5757 - pi_loss: 0.5019 - v_loss: 0.0739\n",
      "Epoch 196/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5770 - pi_loss: 0.5030 - v_loss: 0.0740\n",
      "Epoch 197/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5758 - pi_loss: 0.5022 - v_loss: 0.0736\n",
      "Epoch 198/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5760 - pi_loss: 0.5022 - v_loss: 0.0737\n",
      "Epoch 199/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5762 - pi_loss: 0.5023 - v_loss: 0.0739\n",
      "Epoch 200/200\n",
      "3097/3097 [==============================] - 27s 9ms/step - loss: 0.5758 - pi_loss: 0.5020 - v_loss: 0.0737\n",
      "==========TRAINING convsame=========\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e22404a0f729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnnet_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'==========TRAINING {key}========='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainEx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/fiar/4IAR-RL/classes/beck/beck_nnet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtarget_pis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_pis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtarget_vs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_vs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_boards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget_pis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key,nnet in nnet_dict.items():\n",
    "    print(f'==========TRAINING {key}=========')\n",
    "    nnet.train(trainEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Directory exists! \n",
      "Checkpoint Directory exists! \n",
      "Checkpoint Directory exists! \n",
      "Checkpoint Directory exists! \n"
     ]
    }
   ],
   "source": [
    "for name, nnet in nnet_dict.items():\n",
    "    nnet.save_checkpoint(folder='/scratch/zz737/fiar/sl', filename=f'{name}_Ex_tournament_6_mcts100_cpuct2_id_1_iter55.pth.tar')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====playing against old====\n",
      "Turn  1 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |- - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 0] [ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 0 0\n",
      "Turn  2 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  3 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - X - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 1 0\n",
      "Turn  4 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  5 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- X - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 2 0\n",
      "Turn  6 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - - - - - - - |\n",
      "3 |- X - - - - - - - |\n",
      "-----------------------\n",
      "Turn  7 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - X X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - - - - - - - |\n",
      "3 |- X - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 3 0\n",
      "Game over: Turn  7 Result  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - X X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - - - - - - - |\n",
      "3 |O X - - - - - - - |\n",
      "-----------------------\n",
      "====playing against wl2====\n",
      "Turn  1 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |- - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 0] [ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 0 0\n",
      "Turn  2 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  3 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - X - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 6] [ 3 7] [ 3 8] 1 0\n",
      "Turn  4 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - X - - - |\n",
      "-----------------------\n",
      "Turn  5 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- X - - - - - - - |\n",
      "3 |- - - - - X - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 6] [ 3 7] [ 3 8] 2 0\n",
      "Turn  6 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O X - - - - - - - |\n",
      "3 |- - - - - X - - - |\n",
      "-----------------------\n",
      "Turn  7 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O X - - - - - - - |\n",
      "3 |- - - - - X - - X |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 6] [ 3 7] 3 0\n",
      "Game over: Turn  7 Result  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O X - - - - - - - |\n",
      "3 |O - - - - X - - X |\n",
      "-----------------------\n",
      "====playing against convhead====\n",
      "Turn  1 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |- - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 0] [ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 0 0\n",
      "Turn  2 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  3 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |X - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 0 8\n",
      "Turn  4 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - O |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |X - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  5 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - O |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |X X - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 1 8\n",
      "Turn  6 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - O |\n",
      "1 |- - - - - - - - O |\n",
      "2 |- - - - - - - - - |\n",
      "3 |X X - - - - - - - |\n",
      "-----------------------\n",
      "Turn  7 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - X - O |\n",
      "1 |- - - - - - - - O |\n",
      "2 |- - - - - - - - - |\n",
      "3 |X X - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 7] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 2 8\n",
      "Turn  8 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - X - O |\n",
      "1 |- - - - - - - - O |\n",
      "2 |- - - - - - - - O |\n",
      "3 |X X - - - - - - - |\n",
      "-----------------------\n",
      "Turn  9 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - X - O |\n",
      "1 |- - - - - - - - O |\n",
      "2 |- - - - - - - - O |\n",
      "3 |X X - X - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 7] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 3 2] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 3 8\n",
      "Game over: Turn  9 Result  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - X - O |\n",
      "1 |- - - - - - - - O |\n",
      "2 |- - - - - - - - O |\n",
      "3 |X X - X - - - - O |\n",
      "-----------------------\n",
      "====playing against convsame====\n",
      "Turn  1 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |- - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 0] [ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 0 0\n",
      "Turn  2 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  3 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - X - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 1 0\n",
      "Turn  4 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- - - - - - - X - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  5 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- - - - - - - X - |\n",
      "3 |- - X - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 8] [ 3 0] [ 3 1] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 2 0\n",
      "Turn  6 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - - - - - X - |\n",
      "3 |- - X - - - - - - |\n",
      "-----------------------\n",
      "Turn  7 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - - - - - X X |\n",
      "3 |- - X - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 3 0] [ 3 1] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 3 0\n",
      "Game over: Turn  7 Result  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - - - - - X X |\n",
      "3 |O - X - - - - - - |\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# create mcts and agents \n",
    "n_mcts = 100\n",
    "cpuct = 2\n",
    "tree_args = dotdict({\n",
    "'numMCTSSims': n_mcts,\n",
    "'cpuct': cpuct,\n",
    "})\n",
    "tree_dict = {}\n",
    "ai_dict = {}\n",
    "for player,val_func in nnet_dict.items():\n",
    "    tree_dict[player] = MCTS(game,val_func,tree_args)\n",
    "    ai_dict[player] = lambda x: np.random.choice(np.arange(game.getActionSize()),p=tree_dict[player].getActionProb(x, temp=1/10))\n",
    "\n",
    "from beck.beck_players import HumanBeckPlayer\n",
    "human_p = HumanBeckPlayer(game)\n",
    "p1 = lambda x:human_p.play(x)\n",
    "    \n",
    "for player in nnet_dict.keys():\n",
    "    print(f'====playing against {player}====')\n",
    "    p2 = ai_dict[player]\n",
    "    p2_tree = tree_dict[player]\n",
    "    arena = Arena(p1, p2, game, display=game.display,tree1=None,tree2=p2_tree)\n",
    "    # res=arena.playGames(10,verbose=True)\n",
    "    arena.playGame(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_dict = {}\n",
    "for player,val_func in nnet_dict.items():\n",
    "    tree_dict[player] = MCTS(game,val_func,tree_args)\n",
    "    ai_dict[player] = lambda x: np.random.choice(np.arange(game.getActionSize()),p=tree_dict[player].getActionProb(x, temp=1/10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====playing against res====\n",
      "Turn  1 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |- - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 0] [ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 3] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 0 0\n",
      "Turn  2 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - - - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  3 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |- - - - - - - - - |\n",
      "2 |- - - X - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 5] [ 0 6] [ 0 7] [ 0 8] [ 1 0] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 1 0\n",
      "Turn  4 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - - - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- - - X - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  5 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |- - - X - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 0] [ 2 1] [ 2 2] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 0] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] 2 0\n",
      "Turn  6 Player  -1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - X - - - - - |\n",
      "3 |- - - - - - - - - |\n",
      "-----------------------\n",
      "Turn  7 Player  1\n",
      "   0 1 2 3 4 5 6 7 8 \n",
      "-----------------------\n",
      "0 |O - - - - X - - - |\n",
      "1 |O - - - - - - - - |\n",
      "2 |O - - X - - - - - |\n",
      "3 |X - - - - - - - - |\n",
      "-----------------------\n",
      "[ 0 1] [ 0 2] [ 0 3] [ 0 4] [ 0 6] [ 0 7] [ 0 8] [ 1 1] [ 1 2] [ 1 3] [ 1 4] [ 1 5] [ 1 6] [ 1 7] [ 1 8] [ 2 1] [ 2 2] [ 2 4] [ 2 5] [ 2 6] [ 2 7] [ 2 8] [ 3 1] [ 3 2] [ 3 3] [ 3 4] [ 3 5] [ 3 6] [ 3 7] [ 3 8] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4441b3b18c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0marena\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArena\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# res=arena.playGames(10,verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0marena\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/fiar/4IAR-RL/classes/arena.py\u001b[0m in \u001b[0;36mplayGame\u001b[0;34m(self, verbose, nnet, is_save_moves)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurPlayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCanonicalForm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurPlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mvalids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValidMoves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCanonicalForm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurPlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7cb316f5e673>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbeck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeck_players\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHumanBeckPlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mhuman_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHumanBeckPlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhuman_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnnet_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fiar/4IAR-RL/classes/beck/beck_players.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, board)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"] \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0minput_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0minput_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_move\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/envs/fourinarow/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "player = 'res'\n",
    "print(f'====playing against {player}====')\n",
    "p2 = ai_dict[player]\n",
    "val_func = nnet_dict[player]\n",
    "p2_tree = MCTS(game,val_func,tree_args)\n",
    "arena = Arena(p1, p2, game, display=game.display,tree1=None,tree2=p2_tree)\n",
    "# res=arena.playGames(10,verbose=True)\n",
    "arena.playGame(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_str = '''0 |O - - - - - - - - |\n",
    "1 |O - - - - - - - - |\n",
    "2 |O - - - - - - X - |\n",
    "3 |- - X - - - - - - |'''\n",
    "b = game.get_board_from_xo_str(b_str)\n",
    "b = -b\n",
    "b_str_rep = b.tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [-1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [-1,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=tree_dict['convsame']\n",
    "s=b_str_rep\n",
    "counts = np.array([self.Nsa[(s, a)] if (s, a) in self.Nsa else 0 for a in range(self.game.getActionSize())])\n",
    "vals = np.array([self.Qsa[(s, a)] if (s, a) in self.Qsa else 0 for a in range(self.game.getActionSize())]).astype(np.float32)\n",
    "ps = self.Ps[s]\n",
    "ns = self.Ns[s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14a3b2f69cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3,suppress=True)\n",
    "plt.imshow(vals.reshape(4,9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet_dict['res'].load_checkpoint(folder='/scratch/zz737/fiar/sl', filename='res_Ex_tournament_6_mcts100_cpuct2_id_1_iter55.pth.tar')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
